{
    "BPE_Params": {
        "vocab_size": 18,
        "max_token_length": 8,
        "special_tokens": ["[UNK]"]
    },
    "Data_Params": {
        "sequence_length": 16
    },
    "Train_Params": {
        "epochs": 10,
        "lr": 1e-3,
        "batch_size": 128,
        "device": "cuda:0"
    },
    "Hyperparameters": {
        "k": 32, 
        "blocks": 2,
        "heads": 2
    },
    "Files": {
        "tokenizer": "tiny-llm/tokenizers/debug.json",
        "corpus": "tiny-llm/corpuses/debug.txt",
        "data": "tiny-llm/data/debug.pkl",
        "model": "tiny-llm/trained_models/debug"
    }
}
