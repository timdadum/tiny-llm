{
    "BPE_Params": {
        "vocab_size": 256,
        "max_token_length": 8,
        "special_tokens": ["[UNK]"]
    },
    "Train_Params": {
        "epochs": 25,
        "lr": 2.5e-4,
        "batch_size": 128
    },
    "Baseline_Hyperparams": {
        "embedding_dim": 32, 
        "hidden_size": 128, 
        "num_layers": 3,
        "vocab_size": 255
    }
}
